# import json
# from collections import defaultdict
# import re

# def analyze_lineage(index_file :str, ast_file :str, output_file :str):
 

#     def extract_columns_bruteforce(query: str, stmt_type: str):
#         """
#         Brute force extraction of column names for UPDATE, INSERT, and DELETE statements.
#         Returns a list of column names or ['*'] if none found.
#         stmt_type should be 'UPDATE', 'INSERT', or 'DELETE'.
#         """
#         if not query or not stmt_type:
#             return ["*"]

#         query_upper = query.upper()

#         if stmt_type == "UPDATE":
#             # UPDATE <table> SET col1 = ..., col2 = ...
#             match = re.search(r"\bSET\b(.+?)(\bWHERE\b|$)", query, re.IGNORECASE | re.DOTALL)
#             if match:
#                 set_clause = match.group(1)
#                 columns = [c.split('=')[0].strip() for c in set_clause.split(',') if '=' in c]
#                 return columns or ["*"]

#         elif stmt_type == "INSERT":
#             # INSERT INTO <table> (col1, col2, ...)
#             match = re.search(r"\bINSERT\s+INTO\s+\S+\s*\((.*?)\)", query, re.IGNORECASE | re.DOTALL)
#             if match:
#                 cols_str = match.group(1)
#                 columns = [c.strip() for c in cols_str.split(',') if c.strip()]
#                 return columns or ["*"]

#         elif stmt_type == "DELETE":
#             # DELETE has no explicit column list — return all
#             return ["*"]

#         return ["*"]

#     def extract_table_from_query(query):
#         # crude extraction: look for FROM <table>
#         if not query:
#             return None
#         tokens = query.replace(",", " ").split()
#         for i, token in enumerate(tokens):
#             if token == "FROM" or token== "from" and i + 1 < len(tokens):
#                 table = tokens[i + 1].strip(';')
#                 if not table.startswith("@"):
#                     return table
#         return None

#     def extract_columns_from_select_query(query):
#         """Crude extraction of column names from a SELECT clause in a raw query string."""
#         if not query:
#             return ["*"]
#         query_upper = query.upper()
#         try:
#             select_index = query_upper.find("SELECT")
#             from_index = query_upper.find("FROM")
#             if select_index == -1 or from_index == -1 or from_index < select_index:
#                  return ["*"]

#             # Extract the string between SELECT and FROM
#             cols_str = query[select_index + 6:from_index].strip()
#             if not cols_str or cols_str == '*':
#                 return ["*"]
            
#             # Split by comma and clean up names
#             return [c.strip() for c in cols_str.split(',')]
#         except Exception:
#             return ["*"]
#     def process_expression_condition(proc, expr, table_usage, lineage):
#         if not expr:
#             return
#         if isinstance(expr, dict):
#             expr_type = expr.get("type", "").upper()
#             if expr_type == "RAW_EXPRESSION":
#                 sql = expr.get("expression", "")
#                 if re.search(r"\bselect\b", sql, re.IGNORECASE):
#                     table = extract_table_from_query(sql)
#                     if table:
#                         columns = extract_columns_from_select_query(sql)
#                         lineage[table]["type"] = "table"
#                         lineage[table]["calls"].add(proc)
#                         table_usage[table][proc].append({"op": "read", "cols": columns})
#             elif "op" in expr:
#                 process_expression_condition(proc, expr.get("left"), table_usage, lineage)
#                 process_expression_condition(proc, expr.get("right"), table_usage, lineage)


#     def process_statements(proc: str, stmts: list, table_usage: defaultdict, lineage: defaultdict):
#         """Recursively processes AST statements to find table and column usage."""
#         if not stmts:
#             return

#         for stmt in stmts:
#             stmt_type = stmt.get("type", "").upper()

#             # Handle structured DML statements
#             if stmt_type == "SELECT":
#                 table = stmt.get("from")
#                 #when statements like 'SELECT 'Hi User' as StatusMessage' are used with no from table name mentioned and ast picks it up as a SELECT statement
#                 if table == "DUMMY_TABLE" or table=="NO_TABLE":
#                     continue
#                 if table:
#                     columns = stmt.get("columns", ["*"])
#                     lineage[table]["type"] = "table"
#                     lineage[table]["calls"].add(proc)
#                     table_usage[table][proc].append({"op": "read", "cols": columns})
            
#             elif stmt_type == "SELECT_INTO":
#                 table = stmt.get("table")
                
#                 if table:
#                     columns = stmt.get("columns", ["*"])
#                     lineage[table]["type"] = "table"
#                     lineage[table]["calls"].add(proc)
#                     table_usage[table][proc].append({"op": "read", "cols": columns})

#             elif stmt_type == "UPDATE":
#                 table = stmt.get("table")
#                 if table:
#                     # For UPDATE, the columns are the keys of the "set" object
#                     columns = stmt.get("columns", ["*"])
#                     lineage[table]["type"] = "table"
#                     lineage[table]["calls"].add(proc)
#                     table_usage[table][proc].append({"op": "write", "cols": columns})
            
#             elif stmt_type == "INSERT": # Corrected from "INSERT_INTO" to match schema
#                 table = stmt.get("table")
#                 if table:
#                     columns = stmt.get("columns", ["*"])
#                     lineage[table]["type"] = "table"
#                     lineage[table]["calls"].add(proc)
#                     table_usage[table][proc].append({"op": "write", "cols": columns})
#                 # Handle the read part of an INSERT...SELECT statement
#             if "select_statement" in stmt:
#                     process_statements(proc, [stmt["select_statement"]], table_usage, lineage)
#             # If you think that delete is not  write operation it can be removed later on
#             elif stmt_type == "DELETE":
#                 table = stmt.get("table")
#                 if table:
#                     lineage[table]["type"] = "table"
#                     lineage[table]["calls"].add(proc)
#                     table_usage[table][proc].append({"op": "write", "cols": ["*"]})
#             #if we encounter the RAW_EXPRESSION type of statement
#             #Note - Assuming that RAW_EXPRESSION WILL NEVER CONATIN AN INSERT as it shouldnt contain one.
#             #This is to be tested. It should mostly conatin a select query
#             elif stmt_type == "RAW_EXPRESSION":
#                 expression=stmt.get("expression","")
#                 #only if select exists in the query this will work
#                 if not re.search(r"\bselect\b", expression, re.IGNORECASE):
#                     continue
#                 table=extract_table_from_query(query=expression)
#                 if table :
#                     columns= extract_columns_from_select_query(query=expression)
#                     lineage[table]["type"]="table"
#                     lineage[table]["calls"].add(proc)
#                     table_usage[table][proc].append({"op": "read", "cols": columns})           
#             elif stmt_type == "RAW_SQL":
#                 sql = stmt.get("sql", "") or stmt.get("query", "") or stmt.get("expression", "")
#                 if not sql:
#                     continue

#                 # SELECT
#                 if re.search(r"\\bselect\\b", sql, re.IGNORECASE):
#                     table = extract_table_from_query(sql)
#                     columns = extract_columns_from_select_query(sql)
#                     if table:
#                         lineage[table]["type"] = "table"
#                         lineage[table]["calls"].add(proc)
#                         table_usage[table][proc].append({"op": "read", "cols": columns})

#                 # UPDATE
#                 elif re.search(r"\\bupdate\\b", sql, re.IGNORECASE):
#                     table = extract_table_from_query(sql)
#                     columns = extract_columns_bruteforce(sql, "UPDATE")
#                     if table:
#                         lineage[table]["type"] = "table"
#                         lineage[table]["calls"].add(proc)
#                         table_usage[table][proc].append({"op": "write", "cols": columns})

#                 # INSERT
#                 elif re.search(r"\\binsert\\b", sql, re.IGNORECASE):
#                     table = extract_table_from_query(sql)
#                     columns = extract_columns_bruteforce(sql, "INSERT")
#                     if table:
#                         lineage[table]["type"] = "table"
#                         lineage[table]["calls"].add(proc)
#                         table_usage[table][proc].append({"op": "write", "cols": columns})

#                 # DELETE
#                 elif re.search(r"\\bdelete\\b", sql, re.IGNORECASE):
#                     table = extract_table_from_query(sql)
#                     columns = extract_columns_bruteforce(sql, "DELETE")
#                     if table:
#                         lineage[table]["type"] = "table"
#                         lineage[table]["calls"].add(proc)
#                         table_usage[table][proc].append({"op": "write", "cols": columns})



#                     # In process_statements:
#             if "condition" in stmt:
#                 process_expression_condition(proc, stmt["condition"], table_usage, lineage)


#             # Recursively process all possible nested statement blocks
#             for key in ["then", "else", "body"]:
#                 if key in stmt and isinstance(stmt.get(key), list):
#                     process_statements(proc, stmt[key], table_usage, lineage)
            
#             if stmt_type == "WITH_CTE":
#                 for cte in stmt.get("cte_list", []):
#                     if "query" in cte:
#                         process_statements(proc, [cte["query"]], table_usage, lineage)
#                 if "main_query" in stmt:
#                     process_statements(proc, [stmt["main_query"]], table_usage, lineage)
            
#             if stmt_type == "CASE":
#                 for when_clause in stmt.get("when_clauses", []):
#                     if "then" in when_clause and isinstance(when_clause.get("then"), list):
#                         process_statements(proc, when_clause["then"], table_usage, lineage)

#             if "catch" in stmt:
#                 for handler in stmt.get("catch", []):
#                     if "body" in handler and isinstance(handler.get("body"), list):
#                         process_statements(proc, handler["body"], table_usage, lineage)

#     # Load input files
#     try:
#         with open(index_file) as f:
#             index_data = json.load(f)
#         with open(ast_file) as f:
#             ast_data = json.load(f)
#     except Exception as e:
#         print(f"Exception occured while opening the files {e}\n")
#         return

#     lineage = defaultdict(lambda: {"type": "", "calls": set()})
#     table_usage = defaultdict(lambda: defaultdict(list))

#     # Consolidate all object types from index and ast to establish their existence and type
#     all_db_objects = {}
#     for obj_type, container in index_data.items():
#         if obj_type in ["procedures", "functions", "triggers"]:
#             for name in container.keys():
#                 all_db_objects[name] = {"type": obj_type[:-1]} # "procedures" -> "procedure"

#     for obj_type, container in ast_data.items():
#         key_map = {"procedures": "proc_name", "functions": "func_name", "triggers": "trigger_name"}
#         if obj_type in key_map:
#             for item in container:
#                 name = item.get(key_map[obj_type])
#                 if name:
#                     all_db_objects[name] = {"type": obj_type[:-1]}

#     # Build the main lineage graph from the index file
#     for obj_type, container in index_data.items():
#         if obj_type in ["procedures", "functions", "triggers"]:
#             for name, meta in container.items():
#                 lineage[name]["type"] = all_db_objects[name]["type"]
#                 for called in meta.get("calls", []):
#                     lineage[name]["calls"].add(called)
#                 for table in meta.get("tables", []):
#                     lineage[table]["type"] = "table"
#                     # A table is "called by" the object that uses it
#                     lineage[table]["calls"].add(name)

#     # Process AST to get detailed column-level usage
#     ast_map = {}
#     for obj_type, key_name in [("procedures", "proc_name"), ("functions", "func_name"), ("triggers", "trigger_name")]:
#         for item in ast_data.get(obj_type, []):
#             name = item.get(key_name)
#             if name:
#                 ast_map[name] = item
    
#     for name, ast in ast_map.items():
#         process_statements(name, ast.get("statements", []), table_usage, lineage)

#     # Create a reverse dependency map (who calls whom)
#     called_by_map = defaultdict(lambda: defaultdict(set))
#     for source_name, source_meta in lineage.items():
#         source_type = source_meta.get("type")
#         if not source_type or source_type == "table":
#             continue
#         for target_name in source_meta.get("calls", set()):
#             # e.g., called_by_map['usp_LogEvent']['procedure'].add('usp_UpdateOrderStatus')
#             called_by_map[target_name][source_type].add(source_name)

#     # Format the final output according to the new schema
#     formatted_lineage = {}
#     for name, meta in all_db_objects.items():
#         obj_type = meta["type"]
#         entry = {"type": obj_type}

#         if obj_type == "table":
#             # For tables, 'calls' in our lineage map actually means 'called_by'
#             entry["called_by"] = sorted(list(lineage[name].get("calls", set())))
            
#             columns_list = []
#             if name in table_usage:
#                 for caller_name, ops_list in table_usage[name].items():
#                     caller_type = all_db_objects.get(caller_name, {}).get("type")
#                     if not caller_type: continue

#                     for op_info in ops_list:
#                         for col_name in op_info.get('cols', []):
#                             col_entry = {
#                                 "name": col_name.strip(),
#                                 "usage": op_info.get("op"),
#                                 "caller": caller_name,
#                                 "caller_type": caller_type
#                             }
#                             if col_entry not in columns_list:
#                                 columns_list.append(col_entry)
#             entry["columns"] = columns_list
        
#         elif obj_type in ["procedure", "function"]:
#             entry["calls"] = sorted(list(lineage[name].get("calls", set())))
#             reverse_calls = called_by_map.get(name, {})
#             entry["called_by_procedure"] = sorted(list(reverse_calls.get("procedure", set())))
#             entry["called_by_function"] = sorted(list(reverse_calls.get("function", set())))
#             entry["called_by_trigger"] = sorted(list(reverse_calls.get("trigger", set())))

#         elif obj_type == "trigger":
#             trigger_info = index_data.get("triggers", {}).get(name, {})
#             entry["on_table"] = trigger_info.get("on_table")
#             entry["event"] = trigger_info.get("event")
#             entry["calls"] = sorted(list(lineage[name].get("calls", set())))

#         formatted_lineage[name] = entry

#     with open(output_file, "w") as f:
#         json.dump(formatted_lineage, f, indent=2)

#     print(f"✅ Lineage written to {output_file}")

import json
from collections import defaultdict
import re
import os
import jsonschema
from src.logging_styles import Colours


def analyze_lineage(index_file :str, ast_file :str, output_file :str):


    def extract_columns_bruteforce(query: str, stmt_type: str):
        """
        Brute force extraction of column names for UPDATE, INSERT, and DELETE statements.
        Returns a list of column names or ['*'] if none found.
        stmt_type should be 'UPDATE', 'INSERT', or 'DELETE'.
        """
        if not query or not stmt_type:
            return ["*"]

        query_upper = query.upper()

        if stmt_type == "UPDATE":
            # UPDATE <table> SET col1 = ..., col2 = ...
            match = re.search(r"\bSET\b(.+?)(\bWHERE\b|$)", query, re.IGNORECASE | re.DOTALL)
            if match:
                set_clause = match.group(1)
                columns = [c.split('=')[0].strip() for c in set_clause.split(',') if '=' in c]
                return columns or ["*"]

        elif stmt_type == "INSERT":
            # INSERT INTO <table> (col1, col2, ...)
            match = re.search(r"\bINSERT\s+INTO\s+\S+\s*\((.*?)\)", query, re.IGNORECASE | re.DOTALL)
            if match:
                cols_str = match.group(1)
                columns = [c.strip() for c in cols_str.split(',') if c.strip()]
                return columns or ["*"]

        elif stmt_type == "DELETE":
            # DELETE has no explicit column list — return all
            return ["*"]

        return ["*"]

    def extract_table_from_query(query):
        # crude extraction: look for FROM <table>
        if not query:
            return None
        tokens = query.replace(",", " ").split()
        for i, token in enumerate(tokens):
            if token.upper() == "FROM" and i + 1 < len(tokens):
                table = tokens[i + 1].strip(';')
                if not table.startswith("@"):
                    return table
        return None

    def extract_columns_from_select_query(query):
        """Crude extraction of column names from a SELECT clause in a raw query string."""
        if not query:
            return ["*"]
        query_upper = query.upper()
        try:
            select_index = query_upper.find("SELECT")
            from_index = query_upper.find("FROM")
            if select_index == -1 or from_index == -1 or from_index < select_index:
                return ["*"]

            # Extract the string between SELECT and FROM
            cols_str = query[select_index + 6:from_index].strip()
            if not cols_str or cols_str == '*':
                return ["*"]
            
            # Split by comma and clean up names
            return [c.strip() for c in cols_str.split(',')]
        except Exception:
            return ["*"]
            
    def process_expression_condition(proc, expr, table_usage, lineage):
        if not expr:
            return
        if isinstance(expr, dict):
            expr_type = expr.get("type", "").upper()
            if expr_type == "RAW_EXPRESSION":
                sql = expr.get("expression", "")
                if re.search(r"\bselect\b", sql, re.IGNORECASE):
                    table = extract_table_from_query(sql)
                    if table:
                        columns = extract_columns_from_select_query(sql)
                        lineage[table]["type"] = "table"
                        lineage[table]["calls"].add(proc)
                        table_usage[table][proc].append({"op": "read", "cols": columns})
            elif "op" in expr:
                process_expression_condition(proc, expr.get("left"), table_usage, lineage)
                process_expression_condition(proc, expr.get("right"), table_usage, lineage)


    def process_statements(proc: str, stmts: list, table_usage: defaultdict, lineage: defaultdict):
        """Recursively processes AST statements to find table and column usage."""
        if not stmts:
            return

        for stmt in stmts:
            stmt_type = stmt.get("type", "").upper()

            # Handle structured DML statements
            if stmt_type == "SELECT":
                table = stmt.get("from")
                if table == "DUMMY_TABLE" or table=="NO_TABLE":
                    continue
                if table:
                    columns = stmt.get("columns", ["*"])
                    lineage[table]["type"] = "table"
                    lineage[table]["calls"].add(proc)
                    table_usage[table][proc].append({"op": "read", "cols": columns})
            
            elif stmt_type == "SELECT_INTO":
                # Handle both raw query strings and structured query objects
                query_obj = stmt.get("query", {})
                if isinstance(query_obj, dict):
                    table = query_obj.get("from")
                    columns = query_obj.get("columns", ["*"])
                else: # Fallback for raw string
                    table = extract_table_from_query(str(query_obj))
                    columns = extract_columns_from_select_query(str(query_obj))

                if table:
                    lineage[table]["type"] = "table"
                    lineage[table]["calls"].add(proc)
                    table_usage[table][proc].append({"op": "read", "cols": columns})

            elif stmt_type == "UPDATE":
                table = stmt.get("table")
                if table:
                    # Correctly get columns from the keys of the "set" object
                    columns = list(stmt.get("set", {}).keys()) or ["*"]
                    lineage[table]["type"] = "table"
                    lineage[table]["calls"].add(proc)
                    table_usage[table][proc].append({"op": "write", "cols": columns})
            
            elif stmt_type == "INSERT":
                table = stmt.get("table")
                if table:
                    columns = stmt.get("columns", ["*"])
                    lineage[table]["type"] = "table"
                    lineage[table]["calls"].add(proc)
                    table_usage[table][proc].append({"op": "write", "cols": columns})
                if "select_statement" in stmt:
                    process_statements(proc, [stmt["select_statement"]], table_usage, lineage)

            elif stmt_type == "DELETE":
                table = stmt.get("table")
                if table:
                    lineage[table]["type"] = "table"
                    lineage[table]["calls"].add(proc)
                    table_usage[table][proc].append({"op": "write", "cols": ["*"]})

            elif stmt_type == "RAW_EXPRESSION":
                expression=stmt.get("expression","")
                if not re.search(r"\bselect\b", expression, re.IGNORECASE):
                    continue
                table=extract_table_from_query(query=expression)
                if table :
                    columns= extract_columns_from_select_query(query=expression)
                    lineage[table]["type"]="table"
                    lineage[table]["calls"].add(proc)
                    table_usage[table][proc].append({"op": "read", "cols": columns})
            elif stmt_type == "RAW_SQL":
                sql = stmt.get("sql", "") or stmt.get("query", "") or stmt.get("expression", "")
                if not sql:
                    continue

                if re.search(r"\bselect\b", sql, re.IGNORECASE):
                    table = extract_table_from_query(sql)
                    columns = extract_columns_from_select_query(sql)
                    if table:
                        lineage[table]["type"] = "table"
                        lineage[table]["calls"].add(proc)
                        table_usage[table][proc].append({"op": "read", "cols": columns})

                elif re.search(r"\bupdate\b", sql, re.IGNORECASE):
                    table = extract_table_from_query(sql)
                    columns = extract_columns_bruteforce(sql, "UPDATE")
                    if table:
                        lineage[table]["type"] = "table"
                        lineage[table]["calls"].add(proc)
                        table_usage[table][proc].append({"op": "write", "cols": columns})

                elif re.search(r"\binsert\b", sql, re.IGNORECASE):
                    table = extract_table_from_query(sql)
                    columns = extract_columns_bruteforce(sql, "INSERT")
                    if table:
                        lineage[table]["type"] = "table"
                        lineage[table]["calls"].add(proc)
                        table_usage[table][proc].append({"op": "write", "cols": columns})

                elif re.search(r"\bdelete\b", sql, re.IGNORECASE):
                    table = extract_table_from_query(sql)
                    columns = extract_columns_bruteforce(sql, "DELETE")
                    if table:
                        lineage[table]["type"] = "table"
                        lineage[table]["calls"].add(proc)
                        table_usage[table][proc].append({"op": "write", "cols": columns})

            if "condition" in stmt:
                process_expression_condition(proc, stmt["condition"], table_usage, lineage)

            for key in ["then", "else", "body"]:
                if key in stmt and isinstance(stmt.get(key), list):
                    process_statements(proc, stmt[key], table_usage, lineage)
            
            if stmt_type == "WITH_CTE":
                for cte in stmt.get("cte_list", []):
                    if "query" in cte:
                        process_statements(proc, [cte["query"]], table_usage, lineage)
                if "main_query" in stmt:
                    process_statements(proc, [stmt["main_query"]], table_usage, lineage)
            
            if stmt_type == "CASE":
                for when_clause in stmt.get("when_clauses", []):
                    if "then" in when_clause and isinstance(when_clause.get("then"), list):
                        process_statements(proc, when_clause["then"], table_usage, lineage)

            if "catch" in stmt:
                for handler in stmt.get("catch", []):
                    if "body" in handler and isinstance(handler.get("body"), list):
                        process_statements(proc, handler["body"], table_usage, lineage)

    try:
        with open(index_file) as f:
            index_data = json.load(f)
        with open(ast_file) as f:
            ast_data = json.load(f)
    except Exception as e:
        print(f"Exception occured while opening the files {e}\n")
        return

    lineage = defaultdict(lambda: {"type": "", "calls": set()})
    table_usage = defaultdict(lambda: defaultdict(list))
    all_db_objects = {}

    for obj_type, container in index_data.items():
        if obj_type in ["procedures", "functions", "triggers"]:
            for name in container.keys():
                all_db_objects[name] = {"type": obj_type[:-1]}

    for obj_type, container in ast_data.items():
        key_map = {"procedures": "proc_name", "functions": "func_name", "triggers": "trigger_name"}
        if obj_type in key_map:
            for item in container:
                name = item.get(key_map[obj_type])
                if name:
                    all_db_objects[name] = {"type": obj_type[:-1]}

    for obj_type, container in index_data.items():
        if obj_type in ["procedures", "functions", "triggers"]:
            for name, meta in container.items():
                lineage[name]["type"] = all_db_objects[name]["type"]
                for called in meta.get("calls", []):
                    lineage[name]["calls"].add(called)
                for table in meta.get("tables", []):
                    lineage[table]["type"] = "table"
                    lineage[table]["calls"].add(name)

    ast_map = {}
    for obj_type, key_name in [("procedures", "proc_name"), ("functions", "func_name"), ("triggers", "trigger_name")]:
        for item in ast_data.get(obj_type, []):
            name = item.get(key_name)
            if name:
                ast_map[name] = item
    
    for name, ast in ast_map.items():
        process_statements(name, ast.get("statements", []), table_usage, lineage)

    called_by_map = defaultdict(lambda: defaultdict(set))
    for source_name, source_meta in lineage.items():
        source_type = source_meta.get("type")
        if not source_type or source_type == "table":
            continue
        for target_name in source_meta.get("calls", set()):
            called_by_map[target_name][source_type].add(source_name)

    for name, meta in lineage.items():
        if meta.get("type") == "table" and name not in all_db_objects:
            all_db_objects[name] = {"type": "table"}

    formatted_lineage = {}
    for name, meta in all_db_objects.items():
        obj_type = meta["type"]
        entry = {"type": obj_type}

        if obj_type == "table":
            entry["called_by"] = sorted(list(lineage[name].get("calls", set())))
            columns_list = []
            if name in table_usage:
                for caller_name, ops_list in table_usage[name].items():
                    caller_type = all_db_objects.get(caller_name, {}).get("type")
                    if not caller_type: continue

                    for op_info in ops_list:
                        for col_name in op_info.get('cols', []):
                            col_entry = {
                                "name": col_name.strip(),
                                "usage": op_info.get("op"),
                                "caller": caller_name,
                                "caller_type": caller_type
                            }
                            if col_entry not in columns_list:
                                columns_list.append(col_entry)
            entry["columns"] = columns_list
        
        elif obj_type in ["procedure", "function"]:
            entry["calls"] = sorted(list(lineage[name].get("calls", set())))
            reverse_calls = called_by_map.get(name, {})
            entry["called_by_procedure"] = sorted(list(reverse_calls.get("procedure", set())))
            entry["called_by_function"] = sorted(list(reverse_calls.get("function", set())))
            entry["called_by_trigger"] = sorted(list(reverse_calls.get("trigger", set())))

        elif obj_type == "trigger":
            trigger_info = index_data.get("triggers", {}).get(name, {})
            entry["on_table"] = trigger_info.get("on_table")
            entry["event"] = trigger_info.get("event")
            entry["calls"] = sorted(list(lineage[name].get("calls", set())))

        formatted_lineage[name] = entry
    
    print(f"\n{Colours.YELLOW}--- Validating Generated Lineage Against Schema ---{Colours.RESET}")
    try:
        script_path = os.path.abspath(__file__)
        src_dir = os.path.dirname(script_path)
        tool4_dir = os.path.dirname(src_dir)
        schema_dir = os.path.join(tool4_dir, "schemas")
        lineage_schema_path = os.path.join(schema_dir, "lineage_Schema.json")

        with open(lineage_schema_path, "r") as f:
            lineage_schema = json.load(f)
        
        print("Validating generated lineage data against its schema...")
        jsonschema.validate(instance=formatted_lineage, schema=lineage_schema)
        print(f"{Colours.GREEN}Generated lineage schema validation successful.{Colours.RESET}")

        with open(output_file, "w") as f:
            json.dump(formatted_lineage, f, indent=2)
        print(f"\n{Colours.GREEN}✅ Lineage written to {output_file}{Colours.RESET}")

    except FileNotFoundError:
        print(f"{Colours.RED}Error: Could not find lineage_Schema.json in '{schema_dir}' folder.{Colours.RESET}")
        print(f"{Colours.RED}Skipping output file generation.{Colours.RESET}")
    except jsonschema.exceptions.ValidationError as e:
        print(f"{Colours.RED}Generated lineage schema validation FAILED!{Colours.RESET}")
        print(f"{Colours.RED}Error: {e.message} in object: '{'.'.join(map(str, e.path))}'{Colours.RESET}")
        print(f"{Colours.RED}Output file '{output_file}' was NOT created due to validation error.{Colours.RESET}")
    except Exception as e:
        print(f"{Colours.RED}An unexpected error occurred during final validation or writing: {e}{Colours.RESET}")




















































{
  "procedures": [
    {
      "proc_name": "usp_LogEvent",
      "params": [
        {
          "name": "@eventType",
          "type": "VARCHAR(50)",
          "mode": "IN"
        },
        {
          "name": "@message",
          "type": "VARCHAR(200)",
          "mode": "IN"
        }
      ],
      "return_type": "VOID",
      "variables": [],
      "statements": [
        {
          "type": "INSERT",
          "table": "AuditLog",
          "columns": [
            "EventType",
            "EventMessage"
          ],
          "values": [
            "@eventType",
            "@message"
          ]
        }
      ]
    },
    {
      "proc_name": "usp_UpdateOrderStatus",
      "params": [
        {
          "name": "@orderId",
          "type": "INT",
          "mode": "IN"
        },
        {
          "name": "@newStatus",
          "type": "VARCHAR(20)",
          "mode": "IN"
        }
      ],
      "return_type": "VOID",
      "variables": [],
      "statements": [
        {
          "type": "UPDATE",
          "table": "Orders",
          "set": {
            "Status": "@newStatus"
          },
          "where": {
            "op": "=",
            "left": "OrderID",
            "right": "@orderId"
          }
        },
        {
          "type": "EXECUTE_PROCEDURE",
          "name": "usp_LogEvent",
          "args": [
            "'ORDER_UPDATE'",
            "'Order ' + CONVERT(VARCHAR, @orderId) + ' status changed to ' + @newStatus"
          ]
        }
      ]
    },
    {
      "proc_name": "usp_CloseOrder",
      "params": [
        {
          "name": "@orderId",
          "type": "INT",
          "mode": "IN"
        }
      ],
      "return_type": "VOID",
      "variables": [],
      "statements": [
        {
          "type": "EXECUTE_PROCEDURE",
          "name": "usp_UpdateOrderStatus",
          "args": [
            "@orderId",
            "'CLOSED'"
          ]
        }
      ]
    }
  ],
  "functions": [
    {
      "func_name": "fn_GetOrderTotalWithAudit",
      "params": [
        {
          "name": "@orderId",
          "type": "INT",
          "mode": "IN"
        }
      ],
      "return_type": "DECIMAL(18,2)",
      "variables": [
        {
          "name": "@amount",
          "type": "DECIMAL(18,2)"
        }
      ],
      "statements": [
        {
          "type": "SELECT_INTO",
          "into_vars": [
            "@amount"
          ],
          "query": {
            "type": "SELECT",
            "columns": [
              "Amount"
            ],
            "from": "Orders",
            "where": {
              "op": "=",
              "left": "OrderID",
              "right": "@orderId"
            }
          }
        },
        {
          "type": "EXECUTE_PROCEDURE",
          "name": "usp_LogEvent",
          "args": [
            "'FUNCTION_CALL'",
            "'fn_GetOrderTotalWithAudit called for Order ' + CONVERT(VARCHAR, @orderId)"
          ]
        },
        {
          "type": "RETURN",
          "expression": "@amount"
        }
      ]
    },
    {
      "func_name": "fn_GetOrderWithTax",
      "params": [
        {
          "name": "@orderId",
          "type": "INT",
          "mode": "IN"
        }
      ],
      "return_type": "DECIMAL(18,2)",
      "variables": [
        {
          "name": "@baseAmount",
          "type": "DECIMAL(18,2)"
        },
        {
          "name": "@withTax",
          "type": "DECIMAL(18,2)"
        }
      ],
      "statements": [
        {
          "type": "SET",
          "name": "@baseAmount",
          "value": {
            "op": "FUNCTION_CALL",
            "left": "dbo.fn_GetOrderTotalWithAudit",
            "right": [
              "@orderId"
            ]
          }
        },
        {
          "type": "SET",
          "name": "@withTax",
          "value": {
            "op": "*",
            "left": "@baseAmount",
            "right": "1.1"
          }
        },
        {
          "type": "RETURN",
          "expression": "@withTax"
        }
      ]
    }
  ],
  "triggers": [
    {
      "trigger_name": "trg_AfterInsertOrder",
      "on_table": "Orders",
      "event": "AFTER INSERT",
      "statements": [
        {
          "type": "DECLARE",
          "name": "@orderId",
          "value": "INT"
        },
        {
          "type": "DECLARE",
          "name": "@amount",
          "value": "DECIMAL(18,2)"
        },
        {
          "type": "SELECT_INTO",
          "into_vars": [
            "@orderId",
            "@amount"
          ],
          "query": {
            "type": "SELECT",
            "columns": [
              "OrderID",
              "Amount"
            ],
            "from": "INSERTED"
          }
        },
        {
          "type": "EXECUTE_PROCEDURE",
          "name": "usp_LogEvent",
          "args": [
            "'TRIGGER_INSERT'",
            "'New order ' + CONVERT(VARCHAR, @orderId) + ' inserted with amount ' + CONVERT(VARCHAR, @amount)"
          ]
        },
        {
          "type": "DECLARE",
          "name": "@totalWithTax",
          "value": "DECIMAL(18,2)"
        },
        {
          "type": "SET",
          "name": "@totalWithTax",
          "value": {
            "op": "FUNCTION_CALL",
            "left": "dbo.fn_GetOrderWithTax",
            "right": [
              "@orderId"
            ]
          }
        },
        {
          "type": "EXECUTE_PROCEDURE",
          "name": "usp_LogEvent",
          "args": [
            "'TRIGGER_FUNCTION_CALL'",
            "'Order ' + CONVERT(VARCHAR, @orderId) + ' total with tax: ' + CONVERT(VARCHAR, @totalWithTax)"
          ]
        }
      ]
    }
  ]
}
